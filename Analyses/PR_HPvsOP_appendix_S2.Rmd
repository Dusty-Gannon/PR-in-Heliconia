---
title: "Appendix S2: Testing for generality of pollinator recognition in *Heliconia*"
author: "Gannon et al."
header-includes:
  \usepackage{setspace}
  \onehalfspacing
  \usepackage{bm}
bibliography: /Users/dusty/Documents/zotero_library.bib
output: pdf_document
---

\subsection{Preamble}

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir="~/Documents/Heliconia/Analyses/PR/PR_HPvsOP/")

# packages
    require(ggplot2)
    require(rstan)
    require(loo)
    require(gridExtra)
    require(grid)
    require(knitr)
    require(kableExtra)

#user-defined functions
    post.mode <- function(v){
      q <- which.max(density(v)$y)
      return(density(v)$x[q])
    }

```


\subsection{Summary}

In the dry season (Jan-Mar) of 2017, we conducted experiments comparing pollen tube rates in hand-pollinations to flowers made available to free-ranging pollinators (open-pollination) for six *Heliconia* species. We focused on species that could be found around Las Cruces Biological Station (LCBS), Coto Brus, Costa Rica and in the LCBS living collection. These species were spread broadly across the *Heliconia* phylogeny, representing a range of flower shapes and inflorescence orientations [@iles2016].

 
\subsubsection{Data Preparation}

```{r data, echo=FALSE}

    hpop <- read.csv(file = "~/Documents/Heliconia/Data/PR/HPvsOP_all.csv", header = T, as.is = T)
    
    hpop$f.species <- factor(hpop$Species, levels = unique(hpop$Species))
    hpop$f.treatment <- factor(hpop$Treatment, levels = c("OP", "HP"))
    
```

```{r data supp, eval=FALSE}

    hpop <- read.csv(file = "~/HPvsOP_all.csv", header = T, as.is = T)
    
    hpop$f.species <- factor(hpop$Species, levels = unique(hpop$Species))
    hpop$f.treatment <- factor(hpop$Treatment, levels = c("OP", "HP"))
    
```

  
$~$  

\subsubsection{Model}

  We assume that pollen tube counts in styles are draws from Poisson distributions where $y_i \sim \text{Poisson}(\lambda_i)$, $i=1,2,...,N$. The rate parameter, $\lambda_i$, is a linear combination of the predictor variables and an effect for the individual plant (i.e. random or varying intercepts model) and the day on which the flowers were receptive to pollen. The effects for the plant, which we label $\gamma_{p,s}$, where $p=1,2,...,P_s$ is the total number of plants of species $s$ used in the experiments, are considered to be i.i.d. with mean equal to 0, and species specific variances $\sigma^2_s$ (on the log scale). Similarly, effects of the day, $\delta_d,\ d=1,2,...,D$, are modeled as i.i.d. normal random variables with mean 0 and variance $\upsilon^2$. Thus, we have
  
$$
  \log\lambda_{i} = {\bf X}_{i*} {\bm \beta} + \gamma_{p,s}^{(i)} + \delta_d^{(i)}\ ; \ \ \ p=1,2,...,P_s\ ;\ s=1,2,...,S;\ d=1,2,...,D,
$$
where ${\bf X}_{i*}$ is the $i^{\text{th}}$ row of the model matrix ${\bf X}$. We use the superscript $(i)$ notation to be clear that plant $p$ of species $s$ and day $d$ is associated with observation $i$.

We use a global-local shrinkage model [@tang2018] for the scale parameters of the plant effects, assuming 
$$
\begin{aligned}
\gamma_{1,s},\gamma_{2,s},...,\gamma_{P_s,s} \overset{iid}{\sim} \mathcal{N}(0,\ \sigma_s^2\tau^2)\\
\end{aligned}
$$

for $s=1,2,...,S$ because we did not have enough plants within one species (*H. regalis*) in this dataset to inform inference on the species-specific scale parameters directly. Therefore, we opted for a structure that allows information sharing across a higher level. The effect is, if there is little variance among the scale parameters of the species-specific random effects (i.e. $\tau$ is small), shrinkage towards the model mean will increase (Tang et al. 2018), and even more so for the species for which we had few plants. Information is therefore shared across plants within a species, as well as across species, but not as directly. 

\subsubsection{Priors}

  We use weakly informative priors (priors designed in a such a way as to be intentionally less-informative than a prior reflecting the information actually available [@gelman2006]) for all regression coefficients such that all are independent and normally distributed with mean zero and standard deviation 1.5 (on the log scale). Importantly, a standard deviation of 1.5 was chosen to constrain samplers to biologically reasonable parameter space based on available literature reporting pollen tube rates in *Heliconia*. @kress1983a reports a ~4.08-fold change (a regression coefficient of ~1.407), comparing minimum and maximum pollen tube rates from nine species. Similarly, @pedersen1999 report a ~4.00-fold increase in pollen tube rates in *H. paka* when comparing flowers visited by honeyeaters to cross-pollinations by hand, a ~60-fold increase comparing rates of autogamous selfing to honeyeater pollination, and a 3.3-fold increase in pollen tube rates in *H. laufo* when comparing autogamous selfing to honeyeater pollination. Previous work in this system shows pollen tube rates in H. tortuosa are maximized following visits from violet sabrewing hummingbirds (*Campyloterus hemileucurus*), a ~5.7-fold increase from ineffective pollinators [@betts2015]. A $\mathcal{N}(0,\ 1.5^2)$ prior on regression coefficients on the log scale reflects the presumption that most (95%) of the time, we will not see fold-changes greater than ~20 when comparing pollen tube rates in *Heliconia*. Thus, we think these priors are a good balance among being conservative (concentrating some mass around zero such that signals in the data need to be strong to suggest differences between treatments), vague about prior information, and within the realm of biological plausibility.
  
  For scale parameters, we used regularizing priors to constrain the samplers into biologically reasonable parameter space. We assume 
  
$$
\begin{split}
 \sigma_1,\sigma_2,...,\sigma_s \sim \text{half-Normal}(0,1),\\
 \tau \sim \text{half-Normal}(0,1),
\end{split}
$$
and

$$
\upsilon \sim \text{half-Normal}(0,1).
$$


\subsubsection{Stan model code}

```{stan, eval=FALSE, output.var="poisson_VarInts_day_pl"}

 data{
    
      int<lower=0> N;         //number of observations
      int<lower=0> K;         //number of regression coefficients
      int<lower=0> D;         //number of days
      int<lower=0> P;         //number of plants
      int<lower=0> S;         //number of species in the analysis
      
      int sp[N];        //index for the species sampled in experiment i
      int day[N];        //index for the date
      int pl[N];       //index for the individual plant used in experiment i

      int<lower=0> y[N];      //the data
      matrix[N,K] X;          //design matrix

    }
    
    
  parameters{
  
      vector[K] beta;           //vector of regression coefficients
      real delta_raw[D];        //non-centered parameterization for varying intercepts
      real gamma_raw[P];        //non-centered parameterization for varying intercepts
      real<lower=0> upsilon;      //sd of sd of day-level effects across species
      real<lower=0> sigma[S];     //sd of species specific plant level effect
      real<lower=0> tau;        //sd of sd of plant level effects across species
    
  }
  
  
  transformed parameters{
  
      real<lower=0> lambda[N];

      for(n in 1:N){
        lambda[n] = exp(X[n,]*beta + delta_raw[day[n]]*upsilon + 
        gamma_raw[pl[n]]*sigma[sp[n]]*tau);
      }
  
  }

  model {
  
    //priors
      
      for(k in 1:K){
        beta[k] ~ normal(0, 1.5);
      }
      
      for(s in 1:S){
        sigma[s] ~ normal(0,1);
      }
      
      upsilon ~ normal(0,1);
      tau ~ normal(0, 1);
      
    //model
    
      for(d in 1:D){
        delta_raw[d] ~ normal(0,1);
      }
      
      for(p in 1:P){
        gamma_raw[p] ~ normal(0,1);
      }
      
      for(i in 1:N){
        y[i] ~ poisson(lambda[i]);
      }
      
  }
  
  
  generated quantities{
  
    vector[N] loglik;
    vector[N] y_rep;
    
    for(n in 1:N){
      y_rep[n] = poisson_rng(lambda[n]);
      loglik[n] = poisson_lpmf(y[n] | lambda[n]);
    }

  }

```

\subsubsection{Fitting the model}

```{r run model, eval=FALSE, echo=T}

# cell-means model matrix
  X <- model.matrix(~f.treatment:f.species - 1, data = hpop) 
# dimensions of X
  N <- dim(X)[1]
  K <- dim(X)[2]
# number of days, plants, and species
  D <- length(unique(hpop$Date))
  P <- length(unique(hpop$Plant))
  S <- length(unique(hpop$Species))
# index for the day, plant, and species 
  d_index <- as.integer(factor(as.character(hpop$Date)))
  pl_index <- as.integer(factor(hpop$Plant, levels = unique(hpop$Plant)))
  sp_index <- as.integer(factor(hpop$Species))
# response
  y <- hpop$Tube_Count
 
  mod.data <- list(X=X, N=N, K=K, D=D, P=P, S=S, 
                   day=d_index, pl=pl_index, sp=sp_index, y=y)
  
  mfit <- sampling(poisson_VarInts_day_pl, data=mod.data, 
                   control=list(adapt_delta=0.98), init=0)
  
# model evaluation using loo
  
  mloglik <- extract_log_lik(mfit, parameter_name = "loglik", merge_chains = FALSE)
  mreff <- relative_eff(exp(mloglik))
  
  mloo <- loo(mloglik, r_eff = mreff)
  

```

```{r save fit, echo=FALSE, eval=FALSE}
save(mfit, mloo, file = "~/Documents/Heliconia/Analyses/PR/PR_HPvsOP/Supp_material/model_fit.RData")
```

```{r load fit, echo=FALSE}
load(file = "~/Documents/Heliconia/Analyses/PR/PR_HPvsOP/Supp_material/model_fit.RData")
```
*****
\subsection{Model evaluation}

\subsubsection{Leave-one-out cross validation}

  We assess models using Pareto-smoothed importance sampling for leave-one-out cross validation (PSIS-LOO; @vehtari2017) and posterior predictive checks. Briefly, PSIS-LOO, rather than re-fitting the model using each subset of N-1 data points and assessing the out-of-sample predictive fit (which may be computationally demanding), evaluates the predictive fit using importance ratios. Importance ratios can be computed directly over draws from the posterior distribution of the unknown parameters [@gelfand1992] and are proportional to the ratio of the leave-one-out (LOO) posterior over the posterior distribution estimated from the full data set. Models can then be assessed and compared based on their approximate out-of-sample predictive accuracy (i.e. how well do they predict the held-out sample, given the dataset of $N-1$ other observations?).  
  
  However, because the posterior distribution estimated from the full dataset is likely to have thinner tails and smaller variance, importance ratios may be unstable due to high or even infinite variance. PSIS-LOO therefore fits a generalized Pareto distribution to the upper 20% of the leave-one-out importance ratios (replacing these ratios with the expected values from the fitted Pareto distribution) which stabilizes estimates of predictive accuracy. Furthermore, as a "by-product" of this process, the Pareto shape parameter $\kappa$ provides a convenient diagnostic. If $\kappa \le 0.5$, then the variance of the importance ratios is finite; but, if $\kappa$ > 0.5, then the variance is infinite, suggesting large differences between the posterior as estimated from the full dataset and the LOO dataset, and that the held-out observation would be considered ‘surprising’ under the current model (though @vehtari2017 suggest that values < 0.7 may be okay in practice). Given many datapoints for which this is the case, the model likely does not appropriately capture aspects of the data generating process, and a different model may better fit the data. In combination with the expected log pointwise predictive accuracy, $\widehat{\text{ELPD}}_{\text{loo}}$, models may be compared and assessed.

$~$  

\subsubsection{Posterior predictive checks}

  Another way to assess and compare Bayesian models is through posterior-predictive checks [@gelman2013]. Parameter values for all parameters being estimated are drawn from the posterior distribution $p({\bm \theta} | {\bf y})$, where ${\bm \theta}$ is the vector of parameters and ${\bf y}$ the vector of observations. Then, new data are simulated from the data distribution given the parameter values drawn from the posterior distribution. In this example, values for all regression coefficients and scale parameters are drawn from the posterior, then used to parameterize the model to create $N$ new Poisson rate parameters. Finally, a new observation is drawn from $N$ Poisson distributions with their respective rate parameters to create a predicted dataset of equal length to the one observed. Repeating the process many times yields the posterior-predictive distribution $p(\tilde {\bf y} | {\bf y})$, where $\tilde{\bf y}$ is the vector of predicted data. Calculating a statistic from the observed data (e.g. mean), one can compare the posterior predictive distribution of the statistic to the observed value by computing the statistic for each simulated dataset. If the model fit is good, the observed summary statistic should be within a reasonable range of values based on the predictive distribution (Figure S1).


$~$  
  
  
```{r ppcs, echo=FALSE}
  
  yhat <- as.data.frame(extract(mfit, pars="y_rep"))
  
  prob.eq <- function(v, q){
    mean(v == q)
  }
  prob.gteq <- function(v, q){
    mean(v >= q)
  }

  
#build a data frame for graphical ppc's
  df.ppc <- data.frame(stat=c("p(tilde(y)=0 | y)", "p(tilde(y)=1 | y)",
                              "p(tilde(y)=2 | y)", "p(tilde(y) >= 3 | y)"),
                       obs=c(prob.eq(hpop$Tube_Count,0), prob.eq(hpop$Tube_Count,1),
                             prob.eq(hpop$Tube_Count,2), prob.gteq(hpop$Tube_Count,3)),
                       pred=c(mean(apply(yhat,2,prob.eq, q=0)),
                              mean(apply(yhat,2,prob.eq, q=1)),
                              mean(apply(yhat,2,prob.eq,q=2)),
                              mean(apply(yhat,2,prob.gteq,q=3))),
                       low=c(quantile(apply(yhat,2,prob.eq, q=0), 0.025),
                             quantile(apply(yhat,2,prob.eq, q=1), 0.025),
                             quantile(apply(yhat,2,prob.eq, q=2), 0.025),
                             quantile(apply(yhat,2,prob.gteq, q=3), 0.025)),
                       high=c(quantile(apply(yhat,2,prob.eq, q=0), 0.975),
                              quantile(apply(yhat,2,prob.eq, q=1), 0.975),
                              quantile(apply(yhat,2,prob.eq, q=2), 0.975),
                              quantile(apply(yhat,2,prob.gteq, q=3), 0.975))
  )
  
  df.ppc$stat.f <- factor(df.ppc$stat, levels = 
                            c("p(tilde(y)=0 | y)", "p(tilde(y)=1 | y)",
                              "p(tilde(y)=2 | y)", "p(tilde(y) >= 3 | y)"))
  labs <- c(expression(paste("p(",tilde(y),"=0 | y)", sep='')),
            expression(paste("p(",tilde(y),"=1 | y)", sep='')),
            expression(paste("p(",tilde(y),"=2 | y)", sep='')),
            expression(paste("p(",tilde(y),">=3 | y)", sep='')))
  
  ggplot()+
    geom_errorbarh(data = df.ppc, aes(xmin=low, xmax=high, y=stat.f),
                   height=0.1)+
    geom_point(data = df.ppc, aes(x=pred, y=stat.f), size=4)+
    geom_point(data = df.ppc, aes(x=obs, y=stat.f), color="red", 
               shape=10, size=3)+
    theme_bw()+
    theme(axis.title = element_blank(),
          axis.text = element_text(colour = "black", size = 12))+
    scale_y_discrete(labels=parse(text = labs))
    
  

```

**Figure S1**: Posterior predictive checks for the model described above. The four test statistics from the observed data are: $p(\tilde y = 0 | y),\ p(\tilde y = 1 | y),\ p(\tilde y = 2 | y),$ and $p(\tilde y \ge 3 | y)$. The red marker shows the observed value (proportion of zeros, ones, etc.) calculated from the observed data, points are posterior predictive mean values, and error bars show 95% credible intervals for each posterior predictive distribution.


$~$  

```{r hpop figure, eval=FALSE, echo=FALSE}

  beta <- as.data.frame(extract(mfit, pars="beta"))
  lambda <- exp(beta)

  species <- c("H. hirsuta", "H. metallica", "H. regalis", "H. rostrata", "H. tortuosa", "H. wagneriana")
  trt <- c("OP", "HP")
  
  df.pl <- data.frame(species=rep(species, each=length(trt)),
                      trt=rep(trt,length(species)),
                      estim=apply(lambda, 2, mean),
                      medlow=apply(lambda, 2, quantile, probs=0.1),
                      medhigh=apply(lambda,2,quantile,probs=0.9),
                      low=apply(lambda,2,quantile,probs=0.025),
                      high=apply(lambda,2,quantile,probs=0.975))
  df.pl$species <- factor(df.pl$species, levels = species)
  df.pl$trt <- factor(df.pl$trt, levels = c("HP", "OP"))
  
  plot.theme <- theme(panel.background = element_blank(),
          axis.line = element_line(colour = "black", size = 0.5),
          axis.text = element_text(color = "black", size = 14),
          axis.title.x = element_text(size = 16),
          plot.title = element_text(face = "italic", size=14))
  
hir <-  ggplot(data = df.pl[c(1:2),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylim(c(0,2))+
    ylab("")+
    xlab("")+
    theme(axis.text.x = element_text(colour = "white"))+
    plot.theme+
    ggtitle(label = "H. hirsuta")

scaleFUN <- function(x) sprintf("%.1f", x)

met <-  ggplot(data = df.pl[c(3:4),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylab("")+
    xlab("")+
    theme(axis.text.x = element_text(colour = "white"))+
    plot.theme+
    scale_y_continuous(labels = scaleFUN)+
    ggtitle(label = "H. metallica")


reg <-  ggplot(data = df.pl[c(5:6),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylim(c(0,2))+
    ylab("")+
    xlab("")+
    plot.theme+
    ggtitle(label = "H. regalis")


ros <-  ggplot(data = df.pl[c(7:8),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylim(c(0,2))+
    ylab("")+
    xlab("")+
    theme(axis.text.x = element_text(colour = "white"))+
    plot.theme+
    ggtitle(label = "H. rostrata")

tor <-  ggplot(data = df.pl[c(9:10),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylim(c(0,2))+
    ylab("")+
    xlab("")+
    theme(axis.text.x = element_text(colour = "white"))+
    plot.theme+
    ggtitle(label = "H. tortuosa")


wag <-  ggplot(data = df.pl[c(11:12),], aes(x=trt, y=estim))+
    geom_errorbar(aes(ymin=low, ymax=high), width=0)+
    geom_errorbar(aes(ymin=medlow, ymax=medhigh), size=2, width=0)+
    geom_point(size=5, color="white")+
    geom_point(size=4)+
    ylim(c(0,2))+
    ylab("")+
    xlab("")+
    plot.theme+
    ggtitle(label = "H. wagneriana")

 y_lab <- textGrob(label = "Pollen tubes per style", rot=90, gp=gpar(fontsize=20))
 
 lo_mat <- rbind(c(1,2,2,2,5,5,5),
                 c(1,2,2,2,5,5,5),
                 c(1,2,2,2,5,5,5),
                 c(1,3,3,3,6,6,6),
                 c(1,3,3,3,6,6,6),
                 c(1,3,3,3,6,6,6),
                 c(1,4,4,4,7,7,7),
                 c(1,4,4,4,7,7,7),
                 c(1,4,4,4,7,7,7))
 
png(filename = "~/Documents/Heliconia/Analyses/PR/PR_HPvsOP/figure_1_HPOP.png",
    width = 2100, height = 2700, res = 300)
 grid.arrange(y_lab, hir, met, reg, ros, tor, wag, layout_matrix=lo_mat)
dev.off()

```


\subsection{References}



